{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming is the process of reducing a word to its **word stem** that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP).\n",
    "\n",
    "** Let us say we have a Classification Problem** \n",
    "Find out whether the comment on a product is positive or negative.\n",
    "Reviews(type text) -> eating, eaten, eat -> root word is eat.\n",
    "\n",
    "\n",
    "Stemming helps to reduce the dimensionality of the data.\n",
    "Each word represents a vector in a high dimensional space.\n",
    "\n",
    "#### Stemming Algorithms\n",
    "1. *Porter Stemmer*\n",
    "2. *Snowball Stemmer*\n",
    "3. *Lancaster Stemmer*\n",
    "\n",
    "#### Advantages of Stemming\n",
    "* Reduces the dimensionality of the data.\n",
    "* Helps to find the **stem word**.\n",
    "* Helps to group the words into the same category.\n",
    "\n",
    "#### Disadvantages of Stemming\n",
    "* It removes the context of the some of the words.\n",
    "* It is not always accurate.\n",
    "* It is not suitable for all types of data.\n",
    "\n",
    "\n",
    "**The disadvantages of stemming are overcome by lemmatization.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter Stemmer\n",
    "Porter Stemmer is a stemming algorithm that is used to reduce the words to their root word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating   --->   eat\n",
      "eaten   --->   eaten\n",
      "eater   --->   eater\n",
      "eats   --->   eat\n",
      "ate   --->   ate\n",
      "eat   --->   eat\n",
      "write   --->   write\n",
      "written   --->   written\n",
      "writer   --->   writer\n",
      "writes   --->   write\n",
      "wrote   --->   wrote\n",
      "programmer   --->   programm\n",
      "programming   --->   program\n",
      "program   --->   program\n",
      "programmed   --->   program\n",
      "going   --->   go\n",
      "goes   --->   goe\n",
      "go   --->   go\n",
      "gone   --->   gone\n",
      "history   --->   histori\n",
      "historical   --->   histor\n",
      "historian   --->   historian\n",
      "historically   --->   histor\n",
      "finally   --->   final\n",
      "finalised   --->   finalis\n",
      "final   --->   final\n"
     ]
    }
   ],
   "source": [
    "words = ['eating', 'eaten', 'eater', 'eats', 'ate', 'eat', \n",
    "         'write', 'written', 'writer', 'writes', 'wrote', \n",
    "         'programmer', 'programming', 'program', 'programmed', \n",
    "         \"going\", \"goes\", \"go\", \"gone\", \n",
    "         'history', 'historical', 'historian', 'historically',\n",
    "         'finally', 'finalised', 'final']\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"  --->  \", stemming.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice how the words are stemmed to their root word.\n",
    "* Words like history -> histori => meaning of the word is changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations') # meaning is lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('sitting') # meaning is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegexpStemmer Class\n",
    "\n",
    "RegexpStemmer is used to remove the suffixes from the word, with the help of regular expressions. With the help of this we can easily umplement the Regular Expression Stemmer Algorithms. It basically takes a regular expression and removes any prefix or suffixes from the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "ingeat\n",
      "eating   --->   eat\n",
      "eaten   --->   eaten\n",
      "eater   --->   eater\n",
      "eats   --->   eat\n",
      "ate   --->   ate\n",
      "eat   --->   eat\n",
      "write   --->   writ\n",
      "written   --->   written\n",
      "writer   --->   writer\n",
      "writes   --->   write\n",
      "wrote   --->   wrot\n",
      "programmer   --->   programmer\n",
      "programming   --->   programm\n",
      "program   --->   program\n",
      "programmed   --->   programmed\n",
      "going   --->   go\n",
      "goes   --->   goe\n",
      "go   --->   go\n",
      "gone   --->   gon\n",
      "history   --->   history\n",
      "historical   --->   historical\n",
      "historian   --->   historian\n",
      "historically   --->   historically\n",
      "finally   --->   finally\n",
      "finalised   --->   finalised\n",
      "final   --->   final\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "# ing, s, e, able are the suffixes that are removed from the word.\n",
    "# min=4 means that the word should be at least 4 characters long.   \n",
    "\n",
    "print(reg_stemmer.stem('eating'))   \n",
    "\n",
    "print(reg_stemmer.stem('ingeating'))\n",
    "\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"  --->  \", reg_stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snowball Stemmer\n",
    "Snowball Stemmer is a stemming algorithm that is used to reduce the words to their root word. It is a more advanced version of the Porter Stemmer. It is used to remove the suffixes from the word, with the help of regular expressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating   --->   eat\n",
      "eaten   --->   eaten\n",
      "eater   --->   eater\n",
      "eats   --->   eat\n",
      "ate   --->   ate\n",
      "eat   --->   eat\n",
      "write   --->   write\n",
      "written   --->   written\n",
      "writer   --->   writer\n",
      "writes   --->   write\n",
      "wrote   --->   wrote\n",
      "programmer   --->   programm\n",
      "programming   --->   program\n",
      "program   --->   program\n",
      "programmed   --->   program\n",
      "going   --->   go\n",
      "goes   --->   goe\n",
      "go   --->   go\n",
      "gone   --->   gone\n",
      "history   --->   histori\n",
      "historical   --->   histor\n",
      "historian   --->   historian\n",
      "historically   --->   histor\n",
      "finally   --->   final\n",
      "finalised   --->   finalis\n",
      "final   --->   final\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"  --->  \", snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the output of Snowball Stemmer with the Porter Stemmer.\n",
    "stemming.stem('fairly'), stemming.stem('sportingly') # meaning is lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem('fairly'), snowball_stemmer.stem('sportingly') # meaning is preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
