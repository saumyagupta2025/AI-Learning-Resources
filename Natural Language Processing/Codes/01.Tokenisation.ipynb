{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/saumyagupta/nltk_data', '/Users/saumyagupta/Documents/AI Engineer Roadmap with Projects/.venv/nltk_data', '/Users/saumyagupta/Documents/AI Engineer Roadmap with Projects/.venv/share/nltk_data', '/Users/saumyagupta/Documents/AI Engineer Roadmap with Projects/.venv/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data']\n",
      "['/Users/saumyagupta/nltk_data', '/Users/saumyagupta/Documents/AI Engineer Roadmap with Projects/.venv/nltk_data', '/Users/saumyagupta/Documents/AI Engineer Roadmap with Projects/.venv/share/nltk_data', '/Users/saumyagupta/Documents/AI Engineer Roadmap with Projects/.venv/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data', '/Users/saumyagupta/nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/saumyagupta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt', quiet=False)\n",
    "print(nltk.data.path)\n",
    "\n",
    "nltk.data.path.append('/Users/saumyagupta/nltk_data')\n",
    "\n",
    "# Print the current NLTK data path to verify\n",
    "print(nltk.data.path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punkt directory exists: True\n",
      "Files in punkt directory: ['greek.pickle', 'estonian.pickle', 'turkish.pickle', '.DS_Store', 'polish.pickle', 'PY3', 'russian.pickle', 'czech.pickle', 'portuguese.pickle', 'README', 'dutch.pickle', 'norwegian.pickle', 'malayalam.pickle', 'slovene.pickle', 'english.pickle', 'danish.pickle', 'finnish.pickle', 'swedish.pickle', 'spanish.pickle', 'german.pickle', 'italian.pickle', 'french.pickle']\n"
     ]
    }
   ],
   "source": [
    "# Check if the punkt tokenizer files exist\n",
    "import os\n",
    "punkt_path = os.path.join('/Users/saumyagupta/nltk_data', 'tokenizers', 'punkt')\n",
    "print(f\"Punkt directory exists: {os.path.exists(punkt_path)}\")\n",
    "if os.path.exists(punkt_path):\n",
    "    print(\"Files in punkt directory:\", os.listdir(punkt_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Wow! What an absolutely fantastic day it is outside, isn't it? \\\n",
    "The sun is shining brightly, and the birds are chirping melodiously in the trees. \\\n",
    "I can't help but feel incredibly happy and energized! \\\n",
    "There are so many things to do and see: perhaps I'll go for a long walk in the park, \\\n",
    "or maybe I'll sit by the sparkling lake and read my favorite book. \\\n",
    "Oh, the possibilities are endless! Don't you just love how nature can lift your \\\n",
    "spirits and make everything seem possible? It's truly amazing how a beautiful day can transform our mood and outlook on life. \\\n",
    "Let's make the most of it and create some wonderful memories.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wow!', \"What an absolutely fantastic day it is outside, isn't it?\", 'The sun is shining brightly, and the birds are chirping melodiously in the trees.', \"I can't help but feel incredibly happy and energized!\", \"There are so many things to do and see: perhaps I'll go for a long walk in the park, or maybe I'll sit by the sparkling lake and read my favorite book.\", 'Oh, the possibilities are endless!', \"Don't you just love how nature can lift your spirits and make everything seem possible?\", \"It's truly amazing how a beautiful day can transform our mood and outlook on life.\", \"Let's make the most of it and create some wonderful memories.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "from nltk.data import find\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "punkt_param = PunktParameters()\n",
    "punkt_param.abbrev_types = set(['dr', 'vs', 'mr', 'mrs', 'prof', 'inc'])\n",
    "tokenizer = PunktSentenceTokenizer(punkt_param)\n",
    "\n",
    "# Tokenize the text\n",
    "sentences = tokenizer.tokenize(corpus)\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow!\n",
      "What an absolutely fantastic day it is outside, isn't it?\n",
      "The sun is shining brightly, and the birds are chirping melodiously in the trees.\n",
      "I can't help but feel incredibly happy and energized!\n",
      "There are so many things to do and see: perhaps I'll go for a long walk in the park, or maybe I'll sit by the sparkling lake and read my favorite book.\n",
      "Oh, the possibilities are endless!\n",
      "Don't you just love how nature can lift your spirits and make everything seem possible?\n",
      "It's truly amazing how a beautiful day can transform our mood and outlook on life.\n",
      "Let's make the most of it and create some wonderful memories.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wow', '!', 'What', 'an', 'absolutely', 'fantastic', 'day', 'it', 'is', 'outside', ',', 'isn', \"'\", 't', 'it', '?', 'The', 'sun', 'is', 'shining', 'brightly', ',', 'and', 'the', 'birds', 'are', 'chirping', 'melodiously', 'in', 'the', 'trees', '.', 'I', 'can', \"'\", 't', 'help', 'but', 'feel', 'incredibly', 'happy', 'and', 'energized', '!', 'There', 'are', 'so', 'many', 'things', 'to', 'do', 'and', 'see', ':', 'perhaps', 'I', \"'\", 'll', 'go', 'for', 'a', 'long', 'walk', 'in', 'the', 'park', ',', 'or', 'maybe', 'I', \"'\", 'll', 'sit', 'by', 'the', 'sparkling', 'lake', 'and', 'read', 'my', 'favorite', 'book', '.', 'Oh', ',', 'the', 'possibilities', 'are', 'endless', '!', 'Don', \"'\", 't', 'you', 'just', 'love', 'how', 'nature', 'can', 'lift', 'your', 'spirits', 'and', 'make', 'everything', 'seem', 'possible', '?', 'It', \"'\", 's', 'truly', 'amazing', 'how', 'a', 'beautiful', 'day', 'can', 'transform', 'our', 'mood', 'and', 'outlook', 'on', 'life', '.', 'Let', \"'\", 's', 'make', 'the', 'most', 'of', 'it', 'and', 'create', 'some', 'wonderful', 'memories', '.']\n"
     ]
    }
   ],
   "source": [
    "# Word Tokenisation\n",
    "# Convert para -> words or Convert sentences -> words\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordList = wordpunct_tokenize(corpus)\n",
    "print(wordList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice the wordList contains '!', \"'\", \"?\", ',' , etc.\n",
    "* Apostrophy s gets tokenised into separate token in wordpunkt_tokeniser but not in the word_tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wow', '!', 'What', 'an', 'absolutely', 'fantastic', 'day', 'it', 'is', 'outside', ',', 'is', \"n't\", 'it', '?', 'The', 'sun', 'is', 'shining', 'brightly', ',', 'and', 'the', 'birds', 'are', 'chirping', 'melodiously', 'in', 'the', 'trees.', 'I', 'ca', \"n't\", 'help', 'but', 'feel', 'incredibly', 'happy', 'and', 'energized', '!', 'There', 'are', 'so', 'many', 'things', 'to', 'do', 'and', 'see', ':', 'perhaps', 'I', \"'ll\", 'go', 'for', 'a', 'long', 'walk', 'in', 'the', 'park', ',', 'or', 'maybe', 'I', \"'ll\", 'sit', 'by', 'the', 'sparkling', 'lake', 'and', 'read', 'my', 'favorite', 'book.', 'Oh', ',', 'the', 'possibilities', 'are', 'endless', '!', 'Do', \"n't\", 'you', 'just', 'love', 'how', 'nature', 'can', 'lift', 'your', 'spirits', 'and', 'make', 'everything', 'seem', 'possible', '?', 'It', \"'s\", 'truly', 'amazing', 'how', 'a', 'beautiful', 'day', 'can', 'transform', 'our', 'mood', 'and', 'outlook', 'on', 'life.', 'Let', \"'s\", 'make', 'the', 'most', 'of', 'it', 'and', 'create', 'some', 'wonderful', 'memories', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(corpus)\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "# Here we can see that full stop will not be treated as a separate word but it will be \n",
    "# added to the word itself ('trees.'). But for the last word of the corpus, will have full stop as a\n",
    "# separate token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
